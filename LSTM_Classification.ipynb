{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "import torchmetrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from multiprocessing import cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "\n",
    "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
    "\n",
    "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
    "\n",
    "rcParams['figure.figsize'] = 16, 10\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('./career-con-2019/X_train.csv')\n",
    "y_train = pd.read_csv('./career-con-2019/y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>group_id</th>\n",
       "      <th>surface</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>fine_concrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>concrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>concrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>concrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>soft_tiles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   series_id  group_id        surface\n",
       "0          0        13  fine_concrete\n",
       "1          1        31       concrete\n",
       "2          2        20       concrete\n",
       "3          3        31       concrete\n",
       "4          4        22     soft_tiles"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 1, 1, 6])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(y_train.surface)\n",
    "encoded_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['carpet', 'concrete', 'fine_concrete', 'hard_tiles',\n",
       "       'hard_tiles_large_space', 'soft_pvc', 'soft_tiles', 'tiled',\n",
       "       'wood'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>group_id</th>\n",
       "      <th>surface</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>fine_concrete</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>concrete</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>concrete</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>concrete</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>soft_tiles</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   series_id  group_id        surface  label\n",
       "0          0        13  fine_concrete      2\n",
       "1          1        31       concrete      1\n",
       "2          2        20       concrete      1\n",
       "3          3        31       concrete      1\n",
       "4          4        22     soft_tiles      6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train['label'] = encoded_labels\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['orientation_X',\n",
       " 'orientation_Y',\n",
       " 'orientation_Z',\n",
       " 'orientation_W',\n",
       " 'angular_velocity_X',\n",
       " 'angular_velocity_Y',\n",
       " 'angular_velocity_Z',\n",
       " 'linear_acceleration_X',\n",
       " 'linear_acceleration_Y',\n",
       " 'linear_acceleration_Z']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEATURE_COLUMNS = X_train.columns.tolist()[3:]\n",
    "FEATURE_COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_COLUMNS = y_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking to see if each of the examples has a label in the y_train\n",
    "\n",
    "(X_train.series_id.value_counts() == 128).sum() == len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = []\n",
    "\n",
    "for series_id, group in X_train.groupby('series_id'):\n",
    "  sequence_features = group[FEATURE_COLUMNS]\n",
    "\n",
    "  label = y_train[y_train.series_id == series_id].iloc[0].label\n",
    "\n",
    "  sequences.append((sequence_features, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences, test_sequences = train_test_split(sequences,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3048, 762)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sequences), len(test_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurfaceDataset(Dataset):\n",
    "\n",
    "  def __init__(self,sequences):\n",
    "    self.sequences = sequences\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.sequences)\n",
    "\n",
    "  def __getitem__(self,idx):\n",
    "    sequence, label = self.sequences[idx]\n",
    "    sequence_tensor = torch.Tensor(sequence.to_numpy())\n",
    "    # Ensure label is a tensor with the same dimensions as sequence\n",
    "    label_tensor = torch.Tensor([label]).long()\n",
    "    return dict(\n",
    "        sequence = sequence_tensor,\n",
    "        labels = label_tensor\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurfaceDataModule(pl.LightningDataModule):\n",
    "\n",
    "  def __init__(self, train_sequences, test_sequences, batch_size=8):\n",
    "    super().__init__()\n",
    "    self.batch_size = batch_size\n",
    "    self.train_sequences = train_sequences\n",
    "    self.test_sequences = test_sequences\n",
    "\n",
    "  def setup(self, stage=None):\n",
    "    self.train_dataset = SurfaceDataset(self.train_sequences)\n",
    "    self.test_dataset = SurfaceDataset(self.test_sequences)\n",
    "\n",
    "  def train_dataloader(self):\n",
    "    return DataLoader(\n",
    "      self.train_dataset,\n",
    "      batch_size=self.batch_size,\n",
    "      shuffle=True,\n",
    "      num_workers=cpu_count()\n",
    "    )\n",
    "\n",
    "  def val_dataloader(self):\n",
    "    return DataLoader(\n",
    "      self.test_dataset,\n",
    "      batch_size=self.batch_size,\n",
    "      shuffle=False,\n",
    "      num_workers=cpu_count()\n",
    "    )\n",
    "\n",
    "  def test_dataloader(self):\n",
    "    return DataLoader(\n",
    "      self.test_dataset,\n",
    "      batch_size=self.batch_size,\n",
    "      shuffle=False,\n",
    "      num_workers=cpu_count()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "data_module = SurfaceDataModule(\n",
    "  train_sequences,\n",
    "  test_sequences,\n",
    "  batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceModel(nn.Module):\n",
    "  def __init__(self,n_features, n_classes, n_hidden=256, n_layers=3):\n",
    "    super().__init__()\n",
    "    \n",
    "    self.lstm = nn.LSTM(\n",
    "        input_size=n_features,\n",
    "        hidden_size=n_hidden,\n",
    "        num_layers=n_layers,\n",
    "        batch_first=True,\n",
    "        dropout=0.75\n",
    "    )\n",
    "\n",
    "    self.classifier = nn.Linear(n_hidden,n_classes)\n",
    "\n",
    "  def forward(self,x):\n",
    "    self.lstm.flatten_parameters()\n",
    "    _,(hidden,_) = self.lstm(x)\n",
    "\n",
    "    out = hidden[-1]\n",
    "    return self.classifier(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurfacePredictor(pl.LightningModule):\n",
    "\n",
    "  def __init__(self,n_features:int, n_classes: int):\n",
    "    super().__init__()\n",
    "    self.model = SequenceModel(n_features, n_classes)\n",
    "    self.criterion = nn.CrossEntropyLoss()\n",
    "    self.n_classes = n_classes\n",
    "\n",
    "  def forward(self, x, labels=None):\n",
    "    output = self.model(x)\n",
    "    loss = 0\n",
    "    if labels is not None:\n",
    "        loss = self.criterion(output, labels)\n",
    "    return loss, output\n",
    "\n",
    "  def training_step(self, batch, batch_idx):\n",
    "    sequences = batch[\"sequence\"]\n",
    "    labels = batch[\"labels\"].squeeze()\n",
    "    loss, outputs = self(sequences, labels)\n",
    "    predictions = torch.argmax(outputs,dim=1)\n",
    "    step_accuracy = torchmetrics.functional.accuracy(predictions, labels, task=\"multiclass\", num_classes=self.n_classes)\n",
    "\n",
    "    self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "    self.log(\"train_accuracy\", step_accuracy, prog_bar=True, logger=True)\n",
    "    return {\"loss\": loss, \"accuracy\": step_accuracy}\n",
    "\n",
    "  def validation_step(self, batch, batch_idx):\n",
    "    sequences = batch[\"sequence\"]\n",
    "    labels = batch[\"labels\"].squeeze()\n",
    "    loss, outputs = self(sequences, labels)\n",
    "    predictions = torch.argmax(outputs,dim=1)\n",
    "    step_accuracy = torchmetrics.functional.accuracy(predictions, labels, task=\"multiclass\", num_classes=self.n_classes)\n",
    "\n",
    "    self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
    "    self.log(\"val_accuracy\", step_accuracy, prog_bar=True, logger=True)\n",
    "    return {\"loss\": loss, \"accuracy\": step_accuracy}\n",
    "\n",
    "  def test_step(self, batch, batch_idx):\n",
    "    \n",
    "    sequences = batch[\"sequence\"]\n",
    "    labels = batch[\"labels\"].squeeze()\n",
    "    loss, outputs = self(sequences, labels)\n",
    "    predictions = torch.argmax(outputs,dim=1)\n",
    "    step_accuracy = torchmetrics.functional.accuracy(predictions, labels, task=\"multiclass\", num_classes=self.n_classes)\n",
    "\n",
    "    self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
    "    self.log(\"test_accuracy\", step_accuracy, prog_bar=True, logger=True)\n",
    "    return {\"loss\": loss, \"accuracy\": step_accuracy}\n",
    "\n",
    "  \n",
    "  def configure_optimizers(self):\n",
    "    return optim.Adam(self.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SurfacePredictor(n_features=len(FEATURE_COLUMNS),n_classes=len(label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 14216), started 0:38:50 ago. (Use '!kill 14216' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-bd9c66b3ad3c2d6d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-bd9c66b3ad3c2d6d\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints\",\n",
    "    filename=\"best-checkpoint\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    callbacks=[early_stopping_callback, checkpoint_callback],\n",
    "    max_epochs=N_EPOCHS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/anaconda3/envs/wearables/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory /home/nick/Documents/ss24/ds4w-user-identification/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | model     | SequenceModel    | 1.3 M \n",
      "1 | criterion | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "1.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 M     Total params\n",
      "5.318     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b10533a8f4d34a0c99113b3a81c649cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/anaconda3/envs/wearables/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (48) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "666e7e7de1d546e097cba6d3538d39a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "221254a1e9f44ba889891e4d30e17088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 48: 'val_loss' reached 2.04412 (best 2.04412), saving model to '/home/nick/Documents/ss24/ds4w-user-identification/checkpoints/best-checkpoint-v4.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bcd78aa00704bfa88690d55955fa4cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 96: 'val_loss' reached 2.02912 (best 2.02912), saving model to '/home/nick/Documents/ss24/ds4w-user-identification/checkpoints/best-checkpoint-v4.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98855256a0394888b22bf24558c9fabd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 144: 'val_loss' reached 2.02324 (best 2.02324), saving model to '/home/nick/Documents/ss24/ds4w-user-identification/checkpoints/best-checkpoint-v4.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6dc6baf73e046c0a5ff5a5ddb9ccb42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 192: 'val_loss' reached 2.02271 (best 2.02271), saving model to '/home/nick/Documents/ss24/ds4w-user-identification/checkpoints/best-checkpoint-v4.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ee107d2b578414980c46360d6588eed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 240: 'val_loss' reached 1.99977 (best 1.99977), saving model to '/home/nick/Documents/ss24/ds4w-user-identification/checkpoints/best-checkpoint-v4.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2717998f6634af5a26a22d6217bf8b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 288: 'val_loss' reached 1.98684 (best 1.98684), saving model to '/home/nick/Documents/ss24/ds4w-user-identification/checkpoints/best-checkpoint-v4.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eb14c9930544909918ba8ae5ce85d73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 336: 'val_loss' reached 1.95497 (best 1.95497), saving model to '/home/nick/Documents/ss24/ds4w-user-identification/checkpoints/best-checkpoint-v4.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33f2781c65fb4aae9f530e05d9c736a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 384: 'val_loss' reached 1.92675 (best 1.92675), saving model to '/home/nick/Documents/ss24/ds4w-user-identification/checkpoints/best-checkpoint-v4.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a4ce37e1ee54349a25998352598a7f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 432: 'val_loss' reached 1.87658 (best 1.87658), saving model to '/home/nick/Documents/ss24/ds4w-user-identification/checkpoints/best-checkpoint-v4.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4e29462bbb542e89ec531eab516127f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 480: 'val_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/anaconda3/envs/wearables/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "Restoring states from the checkpoint path at /home/nick/Documents/ss24/ds4w-user-identification/checkpoints/best-checkpoint-v4.ckpt\n",
      "Loaded model weights from the checkpoint at /home/nick/Documents/ss24/ds4w-user-identification/checkpoints/best-checkpoint-v4.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08a360d9eda24ef6a0bddc873e55b443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.29658791422843933\n",
      "        test_loss           1.8765772581100464\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 1.8765772581100464, 'test_accuracy': 0.29658791422843933}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = SurfacePredictor.load_from_checkpoint(\n",
    "  trainer.checkpoint_callback.best_model_path,\n",
    "  n_features=len(FEATURE_COLUMNS),\n",
    "  n_classes=len(label_encoder.classes_)\n",
    ")\n",
    "trained_model.eval()\n",
    "trained_model.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "785bd32f2d804520b288f5bdc9c56393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/762 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm \n",
    "test_dataset = SurfaceDataset(test_sequences)\n",
    "\n",
    "predictions = []\n",
    "labels = []\n",
    "\n",
    "for item in tqdm(test_dataset):\n",
    "  sequence = item[\"sequence\"]\n",
    "  label = item[\"labels\"]\n",
    "\n",
    "  _, output = trained_model(sequence.unsqueeze(dim=0))\n",
    "  prediction = torch.argmax(output, dim=1)\n",
    "  predictions.append(prediction.item())\n",
    "  labels.append(label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                carpet       0.00      0.00      0.00        47\n",
      "              concrete       0.25      0.64      0.36       172\n",
      "         fine_concrete       0.00      0.00      0.00        65\n",
      "            hard_tiles       0.00      0.00      0.00         5\n",
      "hard_tiles_large_space       0.35      0.68      0.46        63\n",
      "              soft_pvc       0.38      0.50      0.44       141\n",
      "            soft_tiles       0.00      0.00      0.00        63\n",
      "                 tiled       0.00      0.00      0.00        89\n",
      "                  wood       0.29      0.02      0.03       117\n",
      "\n",
      "              accuracy                           0.30       762\n",
      "             macro avg       0.14      0.20      0.14       762\n",
      "          weighted avg       0.20      0.30      0.20       762\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/anaconda3/envs/wearables/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/nick/anaconda3/envs/wearables/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/nick/anaconda3/envs/wearables/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    classification_report(labels, predictions, target_names=label_encoder.classes_ )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_confusion_matrix(confusion_matrix):\n",
    "  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
    "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
    "  plt.ylabel('True surface')\n",
    "  plt.xlabel('Predicted surface')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carpet</th>\n",
       "      <th>concrete</th>\n",
       "      <th>fine_concrete</th>\n",
       "      <th>hard_tiles</th>\n",
       "      <th>hard_tiles_large_space</th>\n",
       "      <th>soft_pvc</th>\n",
       "      <th>soft_tiles</th>\n",
       "      <th>tiled</th>\n",
       "      <th>wood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>carpet</th>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concrete</th>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fine_concrete</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hard_tiles</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hard_tiles_large_space</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soft_pvc</th>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soft_tiles</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tiled</th>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wood</th>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        carpet  concrete  fine_concrete  hard_tiles  \\\n",
       "carpet                       0        44              0           0   \n",
       "concrete                     0       110              0           0   \n",
       "fine_concrete                0        50              0           0   \n",
       "hard_tiles                   0         0              0           0   \n",
       "hard_tiles_large_space       0        14              0           0   \n",
       "soft_pvc                     0        63              0           0   \n",
       "soft_tiles                   0        20              0           0   \n",
       "tiled                        0        65              0           0   \n",
       "wood                         0        81              0           0   \n",
       "\n",
       "                        hard_tiles_large_space  soft_pvc  soft_tiles  tiled  \\\n",
       "carpet                                       3         0           0      0   \n",
       "concrete                                    36        23           0      0   \n",
       "fine_concrete                                6         8           0      0   \n",
       "hard_tiles                                   0         5           0      0   \n",
       "hard_tiles_large_space                      43         6           0      0   \n",
       "soft_pvc                                     6        71           0      0   \n",
       "soft_tiles                                   9        34           0      0   \n",
       "tiled                                        7        17           0      0   \n",
       "wood                                        13        21           0      0   \n",
       "\n",
       "                        wood  \n",
       "carpet                     0  \n",
       "concrete                   3  \n",
       "fine_concrete              1  \n",
       "hard_tiles                 0  \n",
       "hard_tiles_large_space     0  \n",
       "soft_pvc                   1  \n",
       "soft_tiles                 0  \n",
       "tiled                      0  \n",
       "wood                       2  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(labels, predictions)\n",
    "df_cm = pd.DataFrame(\n",
    "    cm, index=label_encoder.classes_, columns=label_encoder.classes_\n",
    ")\n",
    "df_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
